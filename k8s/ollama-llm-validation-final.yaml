# =============================================================================
# OLLAMA LLM VALIDATION SERVICE - NO FALLBACK MODE
# =============================================================================

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-config
  namespace: crypto-trading
data:
  OLLAMA_HOST: "0.0.0.0"
  OLLAMA_PORT: "11434"
  OLLAMA_DEFAULT_MODEL: "phi3:3.8b"
  SERVICE_PORT: "8050"
  OLLAMA_URL: "http://ollama:11434"

---
# Ollama Core Service - LLM Runtime
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: crypto-trading
  labels:
    app: ollama
    component: llm-runtime
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
        component: llm-runtime
    spec:
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
          name: http
        env:
        - name: OLLAMA_HOST
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_HOST
        - name: OLLAMA_PORT
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_PORT
        volumeMounts:
        - name: ollama-models
          mountPath: /root/.ollama
        resources:
          requests:
            memory: "4Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /
            port: 11434
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /api/tags
            port: 11434
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        startupProbe:
          httpGet:
            path: /
            port: 11434
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 10
      volumes:
      - name: ollama-models
        hostPath:
          path: /tmp/ollama-models
          type: DirectoryOrCreate

---
apiVersion: v1
kind: Service
metadata:
  name: ollama
  namespace: crypto-trading
  labels:
    app: ollama
spec:
  selector:
    app: ollama
  ports:
  - name: http
    port: 11434
    targetPort: 11434
  type: ClusterIP

---
# Ollama LLM Validation Service - NO FALLBACK MODE
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-llm-validation
  namespace: crypto-trading
  labels:
    app: ollama-llm-validation
    component: llm-validation
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama-llm-validation
  template:
    metadata:
      labels:
        app: ollama-llm-validation
        component: llm-validation
    spec:
      containers:
      - name: ollama-llm-validation
        image: python:3.11-slim
        imagePullPolicy: Never
        ports:
        - containerPort: 8050
          name: http
        command: ["/bin/bash"]
        args:
        - -c
        - |
          pip install fastapi uvicorn mysql-connector-python requests aiohttp
          
          cat > /app/llm_service.py << 'EOF'
          import os
          import logging
          import time
          import json
          import requests
          import aiohttp
          import asyncio
          import mysql.connector
          from datetime import datetime, timedelta
          from fastapi import FastAPI, HTTPException
          import uvicorn
          import threading
          
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)
          
          app = FastAPI(title='Ollama LLM Validation Service - NO FALLBACK')
          OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://ollama:11434')
          DEFAULT_MODEL = os.getenv('OLLAMA_DEFAULT_MODEL', 'phi3:3.8b')
          
          def get_db_connection():
              try:
                  db_config = {
                      'host': os.getenv('DB_HOST', '172.22.32.1'),
                      'user': os.getenv('DB_USER', 'news_collector'),
                      'password': os.getenv('DB_PASSWORD'),
                      'database': os.getenv('DB_NAME_PRICES', 'crypto_prices')
                  }
                  return mysql.connector.connect(**db_config)
              except Exception as e:
                  logger.error(f'Database connection failed: {e}')
                  raise Exception(f'Database connection failed: {e}')
          
          async def check_ollama_models():
              try:
                  async with aiohttp.ClientSession() as session:
                      async with session.get(f'{OLLAMA_URL}/api/tags', timeout=10) as response:
                          if response.status == 200:
                              data = await response.json()
                              models = [model['name'] for model in data.get('models', [])]
                              logger.info(f'Available Ollama models: {models}')
                              return models
                          else:
                              logger.error(f'Failed to get Ollama models: {response.status}')
                              raise Exception(f'Ollama API error: {response.status}')
              except Exception as e:
                  logger.error(f'Error checking Ollama models: {e}')
                  raise Exception(f'Cannot connect to Ollama: {e}')
          
          async def validate_with_ollama(recommendation, market_context):
              try:
                  available_models = await check_ollama_models()
                  
                  if not available_models:
                      raise Exception('No Ollama models available - system must fail')
                  
                  model = available_models[0]
                  logger.info(f'Using Ollama model: {model}')
                  
                  symbol = recommendation['symbol']
                  signal_type = recommendation['signal_type']
                  confidence = recommendation['confidence']
                  amount = recommendation['amount_usd']
                  
                  current_price = market_context.get('current_price', 'N/A')
                  volume_24h = market_context.get('volume_24h', 'N/A')
                  rsi = market_context.get('rsi', 'N/A')
                  sentiment = market_context.get('sentiment', 'N/A')
                  
                  prompt = f'''You are an expert cryptocurrency trading analyst. Analyze this trade recommendation:

SYMBOL: {symbol}
SIGNAL TYPE: {signal_type}
CONFIDENCE: {confidence:.3f}
AMOUNT: ${amount}

MARKET CONTEXT:
- Current Price: ${current_price}
- Volume 24h: {volume_24h}
- RSI: {rsi}
- Market Sentiment: {sentiment}

Provide a JSON response with:
{{
    "validation": "APPROVE|REJECT|MODIFY",
    "confidence": 0.0-1.0,
    "reasoning": "Detailed analysis",
    "risk_assessment": "LOW|MEDIUM|HIGH",
    "suggested_amount": 0.0
}}

Respond only with valid JSON.'''
                  
                  async with aiohttp.ClientSession() as session:
                      payload = {
                          'model': model,
                          'prompt': prompt,
                          'stream': False,
                          'options': {
                              'temperature': 0.2,
                              'top_p': 0.9,
                              'num_ctx': 4096
                          }
                      }
                      
                      async with session.post(f'{OLLAMA_URL}/api/generate', json=payload, timeout=120) as response:
                          if response.status == 200:
                              result = await response.json()
                              response_text = result.get('response', '')
                              
                              try:
                                  json_start = response_text.find('{')
                                  json_end = response_text.rfind('}') + 1
                                  if json_start != -1 and json_end > json_start:
                                      json_text = response_text[json_start:json_end]
                                      validation_result = json.loads(json_text)
                                      
                                      required_fields = ['validation', 'confidence', 'reasoning', 'risk_assessment']
                                      if all(field in validation_result for field in required_fields):
                                          logger.info(f'Ollama validation for {symbol}: {validation_result["validation"]}')
                                          return validation_result
                                      else:
                                          raise Exception(f'Invalid LLM response format')
                              except json.JSONDecodeError as e:
                                  logger.error(f'Failed to parse Ollama JSON response: {e}')
                                  raise Exception(f'Invalid LLM response format: {e}')
                          
                          else:
                              logger.error(f'Ollama API error: {response.status}')
                              raise Exception(f'Ollama API error: {response.status}')
                  
              except Exception as e:
                  logger.error(f'Error in Ollama validation: {e}')
                  raise Exception(f'LLM validation failed: {e}')
          
          def get_market_context(symbol):
              conn = get_db_connection()
              try:
                  cursor = conn.cursor(dictionary=True)
                  cursor.execute('''
                      SELECT current_price, volume_24h, rsi, crypto_sentiment
                      FROM ml_features_materialized 
                      WHERE symbol = %s 
                      ORDER BY timestamp_iso DESC 
                      LIMIT 1
                  ''', (symbol,))
                  data = cursor.fetchone()
                  
                  if data:
                      return {
                          'symbol': symbol,
                          'current_price': data['current_price'],
                          'volume_24h': data['volume_24h'],
                          'rsi': data['rsi'],
                          'sentiment': data['crypto_sentiment']
                      }
                  else:
                      raise Exception(f'No market data found for {symbol}')
              except Exception as e:
                  logger.error(f'Error getting market context for {symbol}: {e}')
                  raise Exception(f'Cannot get market context for {symbol}: {e}')
              finally:
                  if conn:
                      conn.close()
          
          def validate_recommendation(recommendation_id):
              conn = get_db_connection()
              try:
                  cursor = conn.cursor(dictionary=True)
                  cursor.execute('SELECT * FROM trade_recommendations WHERE id = %s', (recommendation_id,))
                  recommendation = cursor.fetchone()
                  
                  if not recommendation:
                      raise Exception(f'Recommendation {recommendation_id} not found')
                  
                  market_context = get_market_context(recommendation['symbol'])
                  
                  loop = asyncio.new_event_loop()
                  asyncio.set_event_loop(loop)
                  validation_result = loop.run_until_complete(validate_with_ollama(recommendation, market_context))
                  loop.close()
                  
                  cursor.execute('''
                      UPDATE trade_recommendations 
                      SET llm_validation = %s,
                          llm_confidence = %s,
                          llm_reasoning = %s,
                          risk_assessment = %s,
                          suggested_amount = %s,
                          validation_timestamp = NOW()
                      WHERE id = %s
                  ''', (
                      validation_result['validation'],
                      validation_result['confidence'],
                      validation_result['reasoning'],
                      validation_result['risk_assessment'],
                      validation_result.get('suggested_amount', recommendation['amount_usd']),
                      recommendation_id
                  ))
                  
                  conn.commit()
                  logger.info(f'Validated recommendation {recommendation_id}: {validation_result["validation"]}')
                  return validation_result
                  
              except Exception as e:
                  logger.error(f'Error validating recommendation {recommendation_id}: {e}')
                  raise Exception(f'LLM validation failed for recommendation {recommendation_id}: {e}')
              finally:
                  if conn:
                      conn.close()
          
          def validate_pending_recommendations():
              conn = get_db_connection()
              try:
                  cursor = conn.cursor(dictionary=True)
                  cursor.execute('''
                      SELECT id FROM trade_recommendations 
                      WHERE execution_status = 'PENDING'
                      AND (llm_validation IS NULL OR llm_validation = '')
                      AND created_at >= NOW() - INTERVAL 30 MINUTE
                      ORDER BY created_at DESC
                      LIMIT 5
                  ''')
                  
                  recommendations = cursor.fetchall()
                  
                  validated_count = 0
                  for rec in recommendations:
                      try:
                          result = validate_recommendation(rec['id'])
                          if result:
                              validated_count += 1
                      except Exception as e:
                          logger.error(f'Failed to validate recommendation {rec["id"]}: {e}')
                  
                  logger.info(f'Validated {validated_count} recommendations with Ollama LLM')
                  
              except Exception as e:
                  logger.error(f'Error in validation cycle: {e}')
                  raise Exception(f'LLM validation cycle failed: {e}')
              finally:
                  if conn:
                      conn.close()
          
          @app.get('/health')
          def health_check():
              return {
                  'status': 'healthy',
                  'service': 'ollama_llm_validation_no_fallback',
                  'ollama_url': OLLAMA_URL,
                  'default_model': DEFAULT_MODEL,
                  'timestamp': datetime.now().isoformat()
              }
          
          @app.post('/validate/{recommendation_id}')
          async def validate_endpoint(recommendation_id: int):
              try:
                  result = validate_recommendation(recommendation_id)
                  return result
              except Exception as e:
                  raise HTTPException(status_code=500, detail=f'LLM validation failed: {str(e)}')
          
          @app.get('/status')
          def get_status():
              conn = get_db_connection()
              try:
                  cursor = conn.cursor()
                  cursor.execute('''
                      SELECT COUNT(*) FROM trade_recommendations 
                      WHERE execution_status = 'PENDING'
                      AND (llm_validation IS NULL OR llm_validation = '')
                  ''')
                  pending_validation = cursor.fetchone()[0]
                  
                  cursor.execute('''
                      SELECT COUNT(*) FROM trade_recommendations 
                      WHERE llm_validation = 'APPROVE'
                      AND execution_status = 'PENDING'
                  ''')
                  approved_pending = cursor.fetchone()[0]
                  
                  return {
                      'status': 'healthy',
                      'pending_validation': pending_validation,
                      'approved_pending': approved_pending,
                      'ollama_url': OLLAMA_URL,
                      'model': DEFAULT_MODEL,
                      'timestamp': datetime.now().isoformat()
                  }
              except Exception as e:
                  return {'status': 'unhealthy', 'error': str(e)}
              finally:
                  if conn:
                      conn.close()
          
          @app.on_event('startup')
          async def startup_event():
              logger.info('Starting Ollama LLM Validation Service - NO FALLBACK MODE...')
              
              try:
                  available_models = await check_ollama_models()
                  if available_models:
                      logger.info(f'Connected to Ollama with models: {available_models}')
                  else:
                      raise Exception('No Ollama models available - system cannot start')
              except Exception as e:
                  logger.error(f'Failed to connect to Ollama: {e}')
                  raise Exception(f'Cannot start without Ollama: {e}')
              
              def validation_worker():
                  while True:
                      try:
                          validate_pending_recommendations()
                          time.sleep(60)
                      except Exception as e:
                          logger.error(f'Error in validation worker: {e}')
                          time.sleep(60)
              
              threading.Thread(target=validation_worker, daemon=True).start()
              logger.info('Ollama LLM Validation Service started - NO FALLBACK MODE')
          
          if __name__ == '__main__':
              uvicorn.run(app, host='0.0.0.0', port=8050)
          EOF
          
          python /app/llm_service.py
        envFrom:
        - configMapRef:
            name: ollama-config
        - configMapRef:
            name: trade-exec-coinbase-config
        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: trade-exec-coinbase-secrets
              key: DB_PASSWORD
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8050
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8050
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

---
apiVersion: v1
kind: Service
metadata:
  name: ollama-llm-validation
  namespace: crypto-trading
  labels:
    app: ollama-llm-validation
spec:
  selector:
    app: ollama-llm-validation
  ports:
  - name: http
    port: 8050
    targetPort: 8050
  type: ClusterIP

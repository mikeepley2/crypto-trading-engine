apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-fallback-config
  namespace: crypto-trading
data:
  NOTIFICATION_WEBHOOK_URL: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
  ADMIN_EMAIL: "admin@yourcompany.com"
  EMAIL_SMTP_SERVER: "smtp.gmail.com"
  EMAIL_SMTP_PORT: "587"
  LLM_CACHE_TTL: "3600"
  OLLAMA_URL: "http://ollama:11434"

---
apiVersion: v1
kind: Secret
metadata:
  name: llm-fallback-secrets
  namespace: crypto-trading
type: Opaque
stringData:
  EMAIL_USERNAME: "alerts@yourcompany.com"
  EMAIL_PASSWORD: "your-app-password"
  SLACK_WEBHOOK_URL: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
  DISCORD_WEBHOOK_URL: "https://discord.com/api/webhooks/YOUR/DISCORD/WEBHOOK"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-fallback-monitor
  namespace: crypto-trading
  labels:
    app: llm-fallback-monitor
    component: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-fallback-monitor
  template:
    metadata:
      labels:
        app: llm-fallback-monitor
        component: monitoring
    spec:
      containers:
      - name: llm-fallback-monitor
        image: python:3.11-slim
        command: ["/bin/bash"]
        args: ["-c", "pip install requests aiohttp openai mysql-connector-python python-dotenv pydantic && cd /app && export PYTHONPATH=/app && python backend/shared/monitor.py"]
        workingDir: /app
        - name: PYTHONPATH
          value: "/app"
        volumeMounts:
        - name: app-code
          mountPath: /app/backend
          readOnly: true
      volumes:
      - name: app-code
        hostPath:
          path: /run/desktop/mnt/host/e/git/aitest/backend
          type: Directory
        env:
        - name: XAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: trading-secrets
              key: XAI_API_KEY
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: trading-secrets
              key: OPENAI_API_KEY
        - name: NOTIFICATION_WEBHOOK_URL
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: NOTIFICATION_WEBHOOK_URL
        - name: ADMIN_EMAIL
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: ADMIN_EMAIL
        - name: EMAIL_SMTP_SERVER
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: EMAIL_SMTP_SERVER
        - name: EMAIL_SMTP_PORT
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: EMAIL_SMTP_PORT
        - name: EMAIL_USERNAME
          valueFrom:
            secretKeyRef:
              name: llm-fallback-secrets
              key: EMAIL_USERNAME
        - name: EMAIL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: llm-fallback-secrets
              key: EMAIL_PASSWORD
        - name: LLM_CACHE_TTL
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: LLM_CACHE_TTL
        - name: OLLAMA_URL
          valueFrom:
            configMapKeyRef:
              name: llm-fallback-config
              key: OLLAMA_URL
        volumeMounts:
        - name: llm-cache
          mountPath: /app/temp/llm_cache
        - name: notification-logs
          mountPath: /app/temp/notifications
        workingDir: /app
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: llm-cache
        emptyDir:
          sizeLimit: 1Gi
      - name: notification-logs
        emptyDir:
          sizeLimit: 100Mi

---
apiVersion: v1
kind: Service
metadata:
  name: llm-fallback-monitor
  namespace: crypto-trading
  labels:
    app: llm-fallback-monitor
spec:
  selector:
    app: llm-fallback-monitor
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP

---
# Future Ollama deployment for local LLM support
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: crypto-trading
  labels:
    app: ollama
    component: local-llm
spec:
  replicas: 0  # Disabled by default - enable when needed
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
        component: local-llm
    spec:
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        livenessProbe:
          httpGet:
            path: /
            port: 11434
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/tags
            port: 11434
          initialDelaySeconds: 15
          periodSeconds: 5
      volumes:
      - name: ollama-data
        persistentVolumeClaim:
          claimName: ollama-storage

---
apiVersion: v1
kind: Service
metadata:
  name: ollama
  namespace: crypto-trading
  labels:
    app: ollama
spec:
  selector:
    app: ollama
  ports:
  - name: http
    port: 11434
    targetPort: 11434
  type: ClusterIP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-storage
  namespace: crypto-trading
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi  # Adjust based on model size requirements
